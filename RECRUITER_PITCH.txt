# Comprehensive Project Documentation: Saylani Medical Analytical Dashboard

## ðŸŽ¯ Project Overview (The "Elevator Pitch")
This is an enterprise-grade **AI-Powered Analytics Platform** designed for healthcare administration. It solves the critical problem of interpreting complex patient data by combining automated data pipelines with a Generative AI interface. 

Instead of manually digging through spreadsheets, administrators can simply ask: *"Which doctor handles the most Dengue cases?"* or *"Show me the patient trend for North District,"* and the system provides instant, accurate answers backed by real-time visualizations.

---

## ï¿½ Core Value Propositions (Why this project matters)
1.  **Safety-First Architecture**: Implemented a "Gatekeeper" layer that strictly filters out medical advice queries (e.g., "cure for flu") to ensure legal compliance and patient safety, redirecting them to professionals.
2.  **Hybrid Intelligence (AI + Deterministic)**: Combines the flexibility of **Google Gemini (LLM)** for natural conversation with the precision of a **Structured Knowledge Base**. This eliminates AI "hallucinations" regarding facts and numbers.
3.  **High Availability (Resilience)**: engineered a robust fallback mechanism. If the AI API fails (latency/downtime), the system automatically switches to a deterministic query engine, ensuring 100% uptime for critical analytics.
4.  **Automated Insights Pipeline**: A one-click ETL (Extract, Transform, Load) process that ingests raw CSVs, performs statistical analysis, and updates the dashboard instantly.

---

## ðŸ—ï¸ Technical Architecture & Workflow

### 1. Data Engineering Layer (ETL Pipeline)
*   **File:** `src/data_cleaning.py`
    *   **Functionality:** Implements the cleaning pipeline. It handles missing values (imputation), standardizes inconsistent naming conventions (e.g., "Fever" vs "fever"), and removes duplicate records.
    *   **Key Tech:** Pandas, NumPy
    *   **Recruiter Note:** "I ensured data integrity first because accurate AI models depend entirely on clean input data."

*   **File:** `src/json_kb_generator.py`
    *   **Functionality:** This is a transformation script that aggregates millions of raw data points into a high-performance **JSON Knowledge Base**. It pre-calculates heavy metrics (Total Patients, Top 10 Diseases per Month) during the build phase.
    *   **Key Tech:** JSON Serialization, Aggregation Algorithms
    *   **Recruiter Note:** "This optimizes performance. Instead of querying the raw DB for every user request, the AI reads from this pre-computed summary, reducing latency by 90%."

### 2. Analytical Layer (EDA & Visualization)
*   **File:** `src/eda_enhanced.py`
    *   **Functionality:** Uses statistical libraries to detect trends. It generates distribution plots (histograms), correlation heatmaps, and time-series graphs, exporting them as static assets for the frontend.
    *   **Key Tech:** Matplotlib, Seaborn, Plotly
    *   **Recruiter Note:** "This provides immediate visual context to the stakeholders alongside the textual AI answers."

### 3. Backend & AI Layer (The "Brain")
*   **File:** `src/llm.py`
    *   **Functionality:** The integration hub for **Google Gemini 2.0**. It manages API authentication, prompt engineering (injecting the JSON context into the system prompt), and response generation.
    *   **Advanced Feature:** Implemented **LRU Caching**. If a user asks a question that was answered recently, it returns the cached response instantly without hitting the API, saving costs.

*   **File:** `src/app.py`
    *   **Functionality:** A high-performance **FastAPI** server acting as the bridge. It exposes REST endpoints (`POST /chat/query`, `GET /analytics`).
    *   **Key Logic:** The **Query Classifier**. It scans user input for medical keywords (symptoms, treatment) vs. analytics keywords (count, trend, ratio) to route the request appropriately.

### 4. Frontend Layer (User Experience)
*   **File:** `src/dashboard.py`
    *   **Functionality:** A reactive web interface built with **Streamlit**. It fetches data from the FastAPI backend and renders interactive charts. It manages the chat state, displaying a "typing..." animation while the backend processes.
    *   **Recruiter Note:** "I chose Streamlit to rapidly prototype a professional UI purely in Python, allowing me to focus more on the backend logic."

---

## ï¿½ï¸ Technical Challenges & Solutions (Interview Gold)

*   **Challenge:** The LLM sometimes gave generic answers or hallucinations.
    *   **Solution:** I implemented **RAG (Retrieval-Augmented Generation)** principles. I force the LLM to use *only* the provided JSON Knowledge Base as its source of truth, creating a "Grounded AI."

*   **Challenge:** External APIs can be slow or inconsistent.
    *   **Solution:** I built a **Fallback Engine** in `llm.py`. If the API times out (>8s) or returns a 500 error, the system quietly switches to a regex-based extractor that pulls data directly from the JSON files. The user never sees an error.

---

## ðŸ’» Tech Stack Summary
*   **Language:** Python 3.10
*   **AI/LLM:** Google Gemini 2.0 Flash (via API)
*   **Backend:** FastAPI, Uvicorn (Asynchronous Server)
*   **Frontend:** Streamlit
*   **Data Ops:** Pandas, NumPy
*   **Format:** JSON (for Knowledge Base), CSV (Raw Data)
